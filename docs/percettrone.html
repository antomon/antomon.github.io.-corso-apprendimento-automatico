<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.552">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Antonio Montano">
<meta name="dcterms.date" content="2024-03-25">
<meta name="description" content="wow">

<title>Corso apprendimento automatico - 2&nbsp; Percettrone</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./summary.html" rel="next">
<link href="./basi-apprendimento-supervisionato.html" rel="prev">
<link href="./favicon.png" rel="icon" type="image/png">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<meta property="og:title" content="Corso apprendimento automatico - 2&nbsp; Percettrone">
<meta property="og:description" content="Corso di apprendimento automatico da zero a primo della classe">
<meta property="og:site_name" content="Corso apprendimento automatico">
<meta name="twitter:title" content="Corso apprendimento automatico - 2&nbsp; Percettrone">
<meta name="twitter:description" content="Corso di apprendimento automatico da zero a primo della classe">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./basi-apprendimento-supervisionato.html">Basi dellâ€™apprendimento supervisionato</a></li><li class="breadcrumb-item"><a href="./percettrone.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Percettrone</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Corso apprendimento automatico</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefazione</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./introduzione.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Introduzione</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./apprendimento-automatico.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Apprendimento automatico</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a href="./basi-apprendimento-supervisionato.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Basi dell'apprendimento supervisionato</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./percettrone.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Percettrone</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./summary.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Summary</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#obiettivo-della-lezione" id="toc-obiettivo-della-lezione" class="nav-link active" data-scroll-target="#obiettivo-della-lezione"><span class="header-section-number">2.1</span> Obiettivo della lezione</a></li>
  <li><a href="#prerequisiti" id="toc-prerequisiti" class="nav-link" data-scroll-target="#prerequisiti"><span class="header-section-number">2.2</span> Prerequisiti</a></li>
  <li><a href="#introduzione" id="toc-introduzione" class="nav-link" data-scroll-target="#introduzione"><span class="header-section-number">2.3</span> Introduzione</a></li>
  <li><a href="#descrizione-dellalgoritmo" id="toc-descrizione-dellalgoritmo" class="nav-link" data-scroll-target="#descrizione-dellalgoritmo"><span class="header-section-number">2.4</span> Descrizione dellâ€™algoritmo</a></li>
  <li><a href="#funzione-di-attivazione" id="toc-funzione-di-attivazione" class="nav-link" data-scroll-target="#funzione-di-attivazione"><span class="header-section-number">2.5</span> Funzione di attivazione</a></li>
  <li><a href="#regola-di-apprendimento" id="toc-regola-di-apprendimento" class="nav-link" data-scroll-target="#regola-di-apprendimento"><span class="header-section-number">2.6</span> Regola di apprendimento</a></li>
  <li><a href="#interpretazione-geometrica" id="toc-interpretazione-geometrica" class="nav-link" data-scroll-target="#interpretazione-geometrica"><span class="header-section-number">2.7</span> Interpretazione geometrica</a></li>
  <li><a href="#deriva" id="toc-deriva" class="nav-link" data-scroll-target="#deriva"><span class="header-section-number">2.8</span> Deriva</a></li>
  <li><a href="#convergenza" id="toc-convergenza" class="nav-link" data-scroll-target="#convergenza"><span class="header-section-number">2.9</span> Convergenza</a></li>
  <li><a href="#generalizzazione" id="toc-generalizzazione" class="nav-link" data-scroll-target="#generalizzazione"><span class="header-section-number">2.10</span> Generalizzazione</a></li>
  <li><a href="#insiemi-di-addestramento-non-separabili" id="toc-insiemi-di-addestramento-non-separabili" class="nav-link" data-scroll-target="#insiemi-di-addestramento-non-separabili"><span class="header-section-number">2.11</span> Insiemi di addestramento non separabili</a></li>
  <li><a href="#ordine-dei-campioni-in-fase-di-addestramento" id="toc-ordine-dei-campioni-in-fase-di-addestramento" class="nav-link" data-scroll-target="#ordine-dei-campioni-in-fase-di-addestramento"><span class="header-section-number">2.12</span> Ordine dei campioni in fase di addestramento</a></li>
  <li><a href="#oltre-la-classificazione-binaria" id="toc-oltre-la-classificazione-binaria" class="nav-link" data-scroll-target="#oltre-la-classificazione-binaria"><span class="header-section-number">2.13</span> Oltre la classificazione binaria</a>
  <ul class="collapse">
  <li><a href="#uno-contro-tutti" id="toc-uno-contro-tutti" class="nav-link" data-scroll-target="#uno-contro-tutti"><span class="header-section-number">2.13.1</span> Uno contro tutti</a></li>
  <li><a href="#generalizzazione-1" id="toc-generalizzazione-1" class="nav-link" data-scroll-target="#generalizzazione-1"><span class="header-section-number">2.13.2</span> Generalizzazione</a></li>
  <li><a href="#uno-contro-uno" id="toc-uno-contro-uno" class="nav-link" data-scroll-target="#uno-contro-uno"><span class="header-section-number">2.13.3</span> Uno contro uno</a></li>
  <li><a href="#utilitÃ " id="toc-utilitÃ " class="nav-link" data-scroll-target="#utilitÃ "><span class="header-section-number">2.13.4</span> UtilitÃ </a></li>
  </ul></li>
  <li><a href="#elementi-chiave-della-lezione" id="toc-elementi-chiave-della-lezione" class="nav-link" data-scroll-target="#elementi-chiave-della-lezione"><span class="header-section-number">2.14</span> Elementi chiave della lezione</a></li>
  <li><a href="#prossimo-passo" id="toc-prossimo-passo" class="nav-link" data-scroll-target="#prossimo-passo"><span class="header-section-number">2.15</span> Prossimo passo</a></li>
  <li><a href="#per-approfondire" id="toc-per-approfondire" class="nav-link" data-scroll-target="#per-approfondire"><span class="header-section-number">2.16</span> Per approfondire</a>
  <ul class="collapse">
  <li><a href="#documenti-storici-sul-percettrone" id="toc-documenti-storici-sul-percettrone" class="nav-link" data-scroll-target="#documenti-storici-sul-percettrone"><span class="header-section-number">2.16.1</span> Documenti storici sul percettrone</a></li>
  <li><a href="#storia-dellapprendimento-delle-macchine" id="toc-storia-dellapprendimento-delle-macchine" class="nav-link" data-scroll-target="#storia-dellapprendimento-delle-macchine"><span class="header-section-number">2.16.2</span> Storia dellâ€™apprendimento delle macchine</a></li>
  <li><a href="#manuali" id="toc-manuali" class="nav-link" data-scroll-target="#manuali"><span class="header-section-number">2.16.3</span> Manuali</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./basi-apprendimento-supervisionato.html">Basi dellâ€™apprendimento supervisionato</a></li><li class="breadcrumb-item"><a href="./percettrone.html"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Percettrone</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Percettrone</span></h1>
<p class="subtitle lead">Unâ€™introduzione</p>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Antonio Montano </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">March 25, 2024</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">March 26, 2024</p>
    </div>
  </div>
    
  </div>
  


</header>


<section id="obiettivo-della-lezione" class="level2" data-number="2.1">
<h2 data-number="2.1" class="anchored" data-anchor-id="obiettivo-della-lezione"><span class="header-section-number">2.1</span> Obiettivo della lezione</h2>
<ol type="1">
<li>Studiamo un algoritmo che Ã¨ una pietra miliare dellâ€™apprendimento delle macchine e che presenta concetti come lâ€™addestramento supervisionato, lâ€™ingegneria delle caratteristiche e la generalizzazione, che sono del tutto generali.</li>
<li>Ãˆ semplice abbastanza perchÃ© si possa essere introdotti in uno dei problemi piÃ¹ importanti dellâ€™apprendimento delle macchine, cioÃ¨ quello della classificazione lineare, nel suo caso piÃ¹ semplice, quella binaria.</li>
</ol>
</section>
<section id="prerequisiti" class="level2" data-number="2.2">
<h2 data-number="2.2" class="anchored" data-anchor-id="prerequisiti"><span class="header-section-number">2.2</span> Prerequisiti</h2>
<ol type="1">
<li>Conoscenza basilari di geometria, algebra e teoria delle funzioni di piÃ¹ variabili.</li>
<li>CapacitÃ  di comprensione delle componenti principali di un algoritmo.</li>
</ol>
</section>
<section id="introduzione" class="level2" data-number="2.3">
<h2 data-number="2.3" class="anchored" data-anchor-id="introduzione"><span class="header-section-number">2.3</span> Introduzione</h2>
<p>Il <strong><code>percettrone</code></strong>, introdotto pubblicamente per la prima volta da Frank Rosenblatt nel 1958, ha giocato un ruolo cruciale nello sviluppo dellâ€™apprendimento delle macchine. Nonostante sia uno dei modelli piÃ¹ semplici di apprendimento supervisionato, la sua introduzione ha segnato lâ€™inizio di unâ€™epoca di grande interesse e sviluppo nel campo delle reti neurali e dellâ€™apprendimento automatico.<br>
Il percettrone Ã¨, in breve, un algoritmo per lâ€™<code>apprendimento supervisionato di classificazioni binarie</code>. In altre parole, riceve in ingresso un vettore di caratteristiche di un modello fisico e produce un singolo risultato binario. Questo risultato Ã¨ determinato dalla somma pesata degli ingressi, che passa attraverso una funzione opportuna, detta di attivazione per riferimento al neurone di McCulloch-Pitts, che ha la forma a gradino per restituire un risultato binario.<br>
La forza del percettrone risiede nella sua capacitÃ  di apprendere i pesi ottimali dai dati di addestramento, cioÃ¨ dati di cui Ã¨ noto perfettamente sia il vettore di ingresso che il risultato (cioÃ¨ la classe binaria, dato che tali risultati possono essere solo due). Lâ€™algoritmo di apprendimento, per ogni campione di addestramento, predice la classe di risultato. Se la predizione Ã¨ corretta, i pesi non vengono modificati. Se la predizione Ã¨ errata, i pesi vengono aggiornati aggiungendo o sottraendo il vettore di ingresso, a seconda che la predizione sia stata troppo bassa o troppo alta.<br>
Rosenblatt ha dimostrato che se i dati di addestramento sono linearmente separabili, allora lâ€™algoritmo di addestramento convergerÃ  a una soluzione che classifica correttamente tutti i campioni di addestramento, in un tempo finito. Block e Novikov hanno anche determinato un limite superiore a tale tempo. Nonostante le sue limitazioni, come lâ€™incapacitÃ  di gestire dati che non sono linearmente separabili, lâ€™importanza del percettrone non deve essere sottovalutata. Ha introdotto lâ€™idea fondamentale che le macchine possono apprendere da dati, e ha gettato le basi per lo sviluppo di modelli di apprendimento automatico piÃ¹ sofisticati, tra cui le reti neurali multistrato e le macchine a vettori di supporto.<br>
Infatti, prima del percettrone, i modelli di neuroni artificiali, come il modello di McCulloch-Pitts, erano statici, nel senso che i loro pesi (o le loro connessioni sinaptiche) erano fissi e non cambiavano nel tempo. Questi modelli potevano eseguire calcoli, ma non erano in grado di adattarsi o apprendere dai dati, cioÃ¨ la conoscenza era â€˜predefinitaâ€™ nella rete neurale. Rosenblatt ha introdotto lâ€™idea che i pesi delle connessioni sinaptiche possano essere modificati in base allâ€™esperienza, in modo simile a come si pensava che i neuroni biologici si adattassero e apprendessero nel cervello. Questo Ã¨ stato un passo fondamentale verso la creazione di modelli di apprendimento delle macchine che potessero imparare dai dati e migliorare cosÃ¬ le loro prestazioni nel tempo.<br>
Rosenblatt Ã¨ probabile che abbia chiamato questo algoritmo, <code>perceptron</code> per sottolineare la sua capacitÃ  di â€˜percepireâ€™ la struttura nei dati di ingresso. Infatti, la parola perceptron richiama â€˜perceptionâ€™, percezione, che Ã¨ il processo cognitivo utilizzato per interpretare le informazioni sensoriali.</p>
<p>The Shallow and the Deep â€“&gt; LIBRO</p>
</section>
<section id="descrizione-dellalgoritmo" class="level2" data-number="2.4">
<h2 data-number="2.4" class="anchored" data-anchor-id="descrizione-dellalgoritmo"><span class="header-section-number">2.4</span> Descrizione dellâ€™algoritmo</h2>
<p>Innanzitutto, distinguiamo tre fasi di esecuzione dellâ€™algoritmo: 1. <code>Fase di addestramento</code>: usiamo un certo numero di coppie di ingressi e corrispondente uscita, che chiameremo, rispettivamente, caratteristiche e classe, per calcolare dei parametri dellâ€™algoritmo, i pesi, fino a che una certa condizione di qualitÃ  globale dellâ€™algoritmo non sia soddisfatta. 2. <code>Fase di validazione</code>: adoperando delle coppie non utilizzate in addestramento, si valuta la qualitÃ  della predizione senza modificare i parametri delâ€™algoritmo. 3. <code>Fase di generalizzazione</code>: diamo in ingresso allâ€™algoritmo delle caratteristiche di cui non conosciamo a priori la classe â€˜veraâ€™ e ne otteniamo una â€˜predettaâ€™.</p>
<p>In generale, le caratteristiche presenti in ogni ingresso sono in un numero prefissato positivo, che puÃ² essere anche arbitrariamente grande, mentre lâ€™uscita sarÃ  sempre un valore unico scelto tra due possibilitÃ . Se rappresentiamo ogni ingresso con <span class="math inline">\(\mathbf{x}\)</span>, la corrispondente classe â€˜veraâ€™ con <span class="math inline">\(y\)</span>, i pesi con <span class="math inline">\(\mathbf{w}\)</span> e, infine, la classe predetta con <span class="math inline">\(\bar{y}\)</span>, allora nel diagramma seguente (Figura 1) Ã¨ riassunta la fase di addestramento del percettrone. {{ insert_image(target, â€˜1â€™, image_location, â€˜Percettrone-Diagramma-addestramento.pngâ€™, â€˜Figura 1: Diagramma del percettrone in fase di addestramentoâ€™, â€˜Diagramma del percettrone in fase di addestramentoâ€™) }}</p>
<p>In ogni esecuzione di addestramento, forniremo in ingresso un gruppo di caratteristiche distinte prese dalla totalitÃ  degli ingressi disponibili, di cui conosciamo anche le rispettive classi. Tutte le coppie di caratteristiche e relative classi compongono lâ€™<strong><code>insieme di addestramento</code></strong> e ogni suo elemento si chiama <strong><code>campione</code></strong>. Nel diagramma le caratteristiche entrano in un nodo dove viene calcolato il valore <span class="math inline">\(z\)</span>, ottenuto come somma pesata delle caratteristiche e usando dei pesi ricavati dallâ€™esecuzione appena precedente. <span class="math inline">\(z\)</span> Ã¨, a sua volta, lâ€™ingresso di un secondo nodo con la funzione <span class="math inline">\(\mathcal{H}\)</span>, detta <code>funzione di attivazione</code>, che ne assegna la classe corrispondente.<br>
Nel caso del percettrone, la funzione di attivazione Ã¨ tale che per valori non negativi la classe Ã¨ <span class="math inline">\(+1\)</span>, altrimenti, per quelli negativi, Ã¨ <span class="math inline">\(-1\)</span>. La funzione <span class="math inline">\(\mathcal{H}\)</span> restituisce sempre valori numerici, ma, generalmente, ad ognuno Ã¨ associato, in esclusiva, un oggetto del modello fisico che ha un nome distintivo, definito come <code>etichetta</code>. Classe ed etichetta sono usati in modo intercambiabile, data la corrispondenza 1 ad 1. Il valore predetto <span class="math inline">\(\bar{y}\)</span> viene confrontato in un terzo nodo col valore reale <span class="math inline">\(y\)</span> corrispondente al vettore di caratteristiche <span class="math inline">\(\mathbf{x}\)</span>: se i due valori concidono, quindi la predizione Ã¨ esatta, allora i pesi non vengono aggiornati, sennÃ² lo sono secondo una semplice formula che prevede di sommare al valore della precedente esecuzione, il prodotto tra un valore costante <span class="math inline">\(\pm 2\eta\)</span>, positivo se il valore corretto era <span class="math inline">\(+1\)</span>, negativo in caso contrario, con <span class="math inline">\(\mathbf{x}\)</span>. Ogni esecuzione Ã¨ una <code>iterazione</code> di un ciclo che prende in ingresso un nuovo campione e il valore dei pesi testÃ© calcolato e continua fino a che non diventi vera una <code>condizione di terminazione</code>.<br>
Ma quando terminano le iterazioni? Lâ€™addestramento terminerÃ  quando la somma degli errori su tutti i campioni sarÃ  nullo, oppure al disotto di un valore prefissato. Nel mentre, i campioni dellâ€™insieme di addestramento saranno usati tutti in un gruppo di iterazioni, definito come <code>epoca</code>, il cui numero Ã¨, evidentemente, pari al numero di campioni dellâ€™insieme di addestramento.<br>
Al termine dellâ€™addestramento sarÃ  ottenuto un insieme di pesi, la cui numerositÃ  Ã¨ pari a quella delle caratteristiche, e tali valori saranno usati, senza alcuna ulteriore modifica, in tutte le esecuzioni della seguente fase di generalizzazione (Figura 2), in cui useremo il percettrone per ottenere classi a priori ignote. {{ insert_image(target, â€˜2â€™, image_location, â€˜Percettrone-Diagramma-generalizzazione.pngâ€™, â€˜Figura 2: Diagramma del percettrone in fase di generalizzazioneâ€™, â€˜Diagramma del percettrone in fase di generalizzazioneâ€™) }}</p>
</section>
<section id="funzione-di-attivazione" class="level2" data-number="2.5">
<h2 data-number="2.5" class="anchored" data-anchor-id="funzione-di-attivazione"><span class="header-section-number">2.5</span> Funzione di attivazione</h2>
<p>Innanzitutto, definiamo formalmente la funzione di attivazione a gradino <span class="math inline">\(\mathcal{H}\)</span> (che Ã¨ una versione modificata della <code>funzione di Heaviside</code>): <span class="math display">\[
\mathcal{H}(z)=\begin{cases} 1, &amp; zâ‰¥Î¸ \\ -1, &amp; z&lt;Î¸ \end{cases}\tag*{\color{blue}{1}}
\]</span> il cui grafico Ã¨ mostrato in Figura 3. Il significato Ã¨ il seguente: se il valore dellâ€™argomento della funzione Ã¨ maggiore o uguale a <span class="math inline">\(\theta\)</span>, allora essa assumerÃ  il valore di <span class="math inline">\(+1\)</span>. Se invece lâ€™argomento sarÃ  minore di <span class="math inline">\(\theta\)</span>, il risultato sarÃ  <span class="math inline">\(-1\)</span>. {{ insert_image(target, â€˜3â€™, image_location, â€˜Percettrone-Funzione-attivazione-gradino.pngâ€™, â€˜Figura 3: Funzione di attivazione a gradinoâ€™, â€˜Funzione di attivazione a gradinoâ€™) }}</p>
<p>Nella definizione Ã¨ presente una soglia predefinita <span class="math inline">\(\theta\)</span>, che permette di inserire un grado di libertÃ  molto importante nellâ€™addestramento, di cui approfondiremo nel seguito. Lâ€™argomento della funzione di attivazione Ã¨ <span class="math inline">\(z=\sum_{j=1}^{n} w_j x_j\)</span>, ottenuto come somma pesata delle caratteristiche in ingresso alla iterazione, ove <span class="math inline">\(n\)</span> Ã¨ il numero delle caratteristiche.<br>
Generalmente, si preferisce una formulazione del tutto equivalente in cui <span class="math inline">\(\mathcal{H}\)</span> ha il gradino nello <span class="math inline">\(0\)</span> dellâ€™asse delle ascisse. A tal fine, definiamo <span class="math inline">\(\bar{z}=z-Î¸\)</span> e riformuliamo la funzione di attivazione: <span class="math display">\[
\mathcal{H}(\bar{z})=\begin{cases} 1, &amp; \bar{z}â‰¥0 \\ -1, &amp; \bar{z}&lt;0 \end{cases},\ \bar{z}=\sum_{j=1}^{N} w_j x_j-Î¸\tag*{\color{blue}{2}}
\]</span> e definendo <span class="math inline">\(w_0=-Î¸\)</span> (chiamato <strong><code>deriva</code></strong>) e <span class="math inline">\(x_0=1\)</span>, quindi rinominando <span class="math inline">\(\bar{z}\)</span> in <span class="math inline">\(z\)</span>, si ricava: <span class="math display">\[
\mathcal{H}(z)=\begin{cases}1, &amp; zâ‰¥0 \\ -1, &amp; z&lt;0 \end{cases},\ z=\sum_{j=0}^{N} w_j x_j\tag*{\color{blue}{3}}
\]</span> dove, sostanzialmente, abbiamo esteso la sommatoria per comprendere anche <span class="math inline">\(\theta\)</span>.<br>
Questa definizione puÃ² essere resa in formato piÃ¹ compatto, introducendo i vettori <span class="math inline">\(\mathbf{w}\)</span> per i pesi e <span class="math inline">\(\mathbf{x}\)</span> per le caratteristiche: <span class="math display">\[
\mathbf{w}=\begin{pmatrix} w_0 \\ w_1 \\ \vdots \\ w_n \end{pmatrix},\ \mathbf{x}=\begin{pmatrix} 1 \\ x_1 \\ \vdots \\ x_n \end{pmatrix}\tag*{\color{blue}{4}}
\]</span> dove ricordiamo che le caratteristiche â€˜realiâ€™ del modello sono sempre in numero di <span class="math inline">\(n\)</span>, mentre i due vettori hanno dimensione <span class="math inline">\(n+1\)</span>. Pertanto, la funzione di attivazione puÃ² essere riscritta utilizzando il prodotto scalare tra i due vettori dei pesi e delle caratteristiche, cioÃ¨ <span class="math inline">\(z=\sum_{j=0}^{N} w_j x_j=\langle\mathbf{w},\mathbf{x}\rangle\)</span>: <span class="math display">\[
\mathcal{H}(z)=\begin{cases}1, &amp; zâ‰¥0 \\ -1, &amp; z&lt;0 \end{cases},\ z=\langle\mathbf{w},\mathbf{x}\rangle.\tag*{\color{blue}{5}}
\]</span></p>
</section>
<section id="regola-di-apprendimento" class="level2" data-number="2.6">
<h2 data-number="2.6" class="anchored" data-anchor-id="regola-di-apprendimento"><span class="header-section-number">2.6</span> Regola di apprendimento</h2>
<p>Nella fase di addestramento, il percettrone â€˜apprendeâ€™ i pesi che saranno usati in generalizzazione, cioÃ¨ lâ€™algoritmo determina il vettore <span class="math inline">\(\mathbf{w}\)</span>, sotto la <code>supervisione</code> di un â€˜insegnanteâ€™ che fornisce lâ€™insieme di addestramento e osserva le predizioni (donde la caratteristica dellâ€™algoritmo di <code>apprendimento supervisionato</code>).<br>
Introduciamo alcune notazioni: lâ€™insieme di addestramento <span class="math inline">\(\Xi\)</span> sia composto da <span class="math inline">\(N\)</span> elementi <span class="math inline">\((\mathbf{x}^i, y_i)\)</span> (i campioni), ognuno con due valori, il vettore delle <span class="math inline">\(n+1\)</span> caratteristiche reali <span class="math inline">\(\mathbf{x}^i\)</span> e la sua classe <span class="math inline">\(y^i\)</span> che puÃ² assumere solo i valori <span class="math inline">\(\pm1\)</span>: <span class="math display">\[
(\mathbf{x}^1, y_1), \dots, (\mathbf{x}^N, y_N)\in\Xi\tag*{\color{blue}{6}}
\]</span> con <span class="math inline">\(N\)</span> numero positivo, <span class="math inline">\(\eta\)</span> sia il <strong><code>tasso di apprendimento</code></strong> con <span class="math inline">\(0&lt;\etaâ‰¤1\)</span>, <span class="math inline">\(K\)</span> sia un numero intero positivo che identifichi lâ€™iterazione corrente, e <span class="math inline">\(\bar{y}_K\)</span> denoti il risultato dellâ€™algoritmo allâ€™iterazione <span class="math inline">\(K\)</span>, cioÃ¨ la classe predetta, allora i passi che il percettrone esegue nella fase di apprendimento, sono riassunti nella cosiddetta <strong><code>regola di apprendimento</code></strong>:</p>
<blockquote class="blockquote">
<p><strong><code>Regola di apprendimento del percettrone</code></strong> 1. Inizializza i pesi <span class="math inline">\(\mathbf{w}^0\)</span> a <span class="math inline">\(0\)</span> oppure a piccoli valori casuali, definisci un tasso di apprendimento <span class="math inline">\(\eta\)</span> e un numero massimo di iterazioni <span class="math inline">\(\bar{K}\)</span> o un numero massimo di epoche <span class="math inline">\(\bar{E}\)</span>. 2. Per ogni epoca <span class="math inline">\(E\)</span>: 1. Per ogni campione <span class="math inline">\((\mathbf{x}^\kappa, y_\kappa)\)</span> dellâ€™insieme di addestramento (<span class="math inline">\(1â‰¤\kappaâ‰¤N\)</span> Ã¨ lâ€™indice positivo sullâ€™insieme di addestramento, <span class="math inline">\(E\)</span> Ã¨ lâ€™indice positivo di epoche, <span class="math inline">\(N\)</span> la dimensione dellâ€™insieme di addestramento e <span class="math inline">\(K=EN+\kappa\)</span> il totale delle iterazioni compiute): 1. Calcola la predizione della classe corrispondente a <span class="math inline">\(\mathbf{x}^\kappa\)</span>: <span class="math display">\[
     \bar{y}_K=\mathcal{H}\left(\sum_{j=0}^{n} w_j^{K-1} x_j^\kappa\right).\tag*{\color{blue}{7}}
     \]</span> 2. Aggiorna i pesi <span class="math inline">\(\mathbf{w}^K\)</span> secondo la formula: <span class="math display">\[
      \mathbf{w}^K=\mathbf{w}^{K-1}+\eta(y_\kappa-\bar{y}_K)\mathbf{x}^\kappa.\tag* {\color{blue}{8}}
      \]</span> 2. Continua fino alla prima occorrenza di una tra le due condizioni seguenti: non vi siano piÃ¹ errori di predizione sullâ€™insieme di addestramento, cioÃ¨ <span class="math inline">\(y_\kappa-\bar{y}_K=0\ \forall \kappa\)</span>, cioÃ¨ in una intera epoca, oppure finchÃ© non sia raggiunto il numero massimo di iterazioni <span class="math inline">\(\bar{K}\)</span> o il numero massimo di epoche <span class="math inline">\(\bar{E}\)</span> (dove <span class="math inline">\(\bar{K}=N\bar{E}\)</span>). 3. Prendi il vettore dei pesi <span class="math inline">\(\mathbf{w}\)</span> per classificare caratteristiche con etichetta ignota nella fase di generalizzazione.</p>
</blockquote>
<p>Il tasso di apprendimento <span class="math inline">\(\eta\)</span> e il numero massimo di iterazioni <span class="math inline">\(\bar{K}\)</span> sono detti <strong><code>iperparametri</code></strong>, dato che non sono modificati dalla regola di apprendimento, ma ricavati con tecniche aggiuntive ad hoc. Le iterazioni sono tali da applicare tutto lâ€™insieme di addestramento un certo numero intero di volte, quindi <span class="math inline">\(\bar{K}=E\cdot N\)</span>.<br>
Si nota che: * Se il percettrone predice correttamente la classe, allora <span class="math inline">\(y_\kappa-\bar{y}_K=0\)</span>, quindi i pesi rimangono invariati. * Se il percettrone effettua una predizione erronea, allora <span class="math display">\[
\mathbf{w}^K-\mathbf{w}^{K-1}=\eta (y_\kappa-\bar{y}_K)\mathbf{x}^\kappa=\begin{cases}\eta (1-(-1))\mathbf{x}^\kappa=2\eta \mathbf{x}^\kappa &amp; y_\kappa=1,\ \bar{y}_K=-1 \\ \eta (-1-(1))\mathbf{x}^\kappa=-2\eta \mathbf{x}^\kappa &amp; y_\kappa=-1,\ \bar{y}_K=1 \end{cases}\tag*{\color{blue}{9}}
\]</span> quindi per <span class="math inline">\(y_\kappa=1\)</span> i pesi si incrementano di una frazione positiva del vettore delle caratteristiche, mentre per <span class="math inline">\(y_\kappa=-1\)</span> di una frazione negativa, la cui entitÃ  dipende da <span class="math inline">\(\eta\)</span>.</p>
</section>
<section id="interpretazione-geometrica" class="level2" data-number="2.7">
<h2 data-number="2.7" class="anchored" data-anchor-id="interpretazione-geometrica"><span class="header-section-number">2.7</span> Interpretazione geometrica</h2>
<p>Possiamo interpretare la <span class="math inline">\(\color{blue}\fbox{5}\)</span>, come lâ€™esistenza di una frontiera, per cui se un vettore delle caratteristiche Ã¨ â€˜sopraâ€™ di essa, allora la classe corrispondente Ã¨ <span class="math inline">\(+1\)</span> , se al disotto allora sarÃ  <span class="math inline">\(-1\)</span>. Tale frontiera Ã¨ definita da <span class="math inline">\(\langle\mathbf{w},\mathbf{x}\rangle=0\)</span> o, equivalentemente <span class="math inline">\(\sum_{j=0}^{n} w_j x_j=0\)</span>, che possiamo riscrivere, ricordando che <span class="math inline">\(x_0=1\)</span>, come <span class="math inline">\(w_0+x_1w_1+\dots+x_nw_n=0\)</span> che corrisponde ad un punto su una retta per <span class="math inline">\(n=1\)</span>, una retta nel piano per <span class="math inline">\(n=2\)</span>, un piano nello spazio tridimensionale per <span class="math inline">\(n=3\)</span> e un iperpiano in <span class="math inline">\(\mathbb{R}^n\)</span> per <span class="math inline">\(n&gt;3\)</span>.<br>
Scegliamo <span class="math inline">\(n=2\)</span> per poter visualizzare i vettori delle caratteristiche e la frontiera. Un vettore <span class="math inline">\(\mathbf{x}\)</span>, cosÃ¬ come definito in <span class="math inline">\(\color{blue}\fbox{4}\)</span>, lo disegniamo come un punto di coordinate <span class="math inline">\((x_1,x_2)\)</span> e la frontiera di equazione <span class="math inline">\(w_0+x_1w_1+x_2w_2=0\)</span>, come una retta. Sappiamo che, ad ogni iterazione, i tre pesi <span class="math inline">\(w_0,w_1,w_2\)</span> possono assumere dei nuovi valori e, al termine dellâ€™addestramento, avranno quelli definitivi da usare nella fase di generalizzazione.<br>
Nella Figura 4, tutti i punti sopra o sulla retta (sfondo rosa) sono tali che <span class="math inline">\(w_0+x_1w_1+x_2w_2â‰¥0\)</span>, quindi hanno classe <span class="math inline">\(+1\)</span>, mentre per quelli per cui Ã¨ <span class="math inline">\(w_0+x_1w_1+x_2w_2&lt;0\)</span> la classe Ã¨ <span class="math inline">\(-1\)</span> (sfondo azzurro). {{ insert_image(target, â€˜4â€™, image_location, â€˜Percettrone-Frontiera-decisione.pngâ€™, â€˜Figura 4: Spazio bidimensionale delle caratteristiche e frontiera di decisioneâ€™, â€˜Spazio bidimensionale delle caratteristiche e frontiera di decisioneâ€™) }}</p>
<p>Quindi, la retta <span class="math inline">\(w_0+x_1w_1+x_2w_2=0\)</span> si comporta come una vera e propria <strong><code>frontiera di decisione</code></strong>, giacchÃ© la posizione relativa del vettore delle caratteristiche rispetto alla retta, determina la classe predetta che gli corrisponde. Proprio perchÃ© la frontiera di decisione Ã¨ una linea, allora il percettrone Ã¨ definito come un <strong><code>classificatore lineare</code></strong>.<br>
In pratica, lâ€™addestramento consiste nel muovere la retta (o per un numero di caratteristiche <span class="math inline">\(n&gt;2\)</span>, un piano o un iperpiano) nello spazio bidimensionale (rispettivamente, nello spazio tridimensionale o multidimensionale), in modo da dividerlo perchÃ© tutti i punti con classe <span class="math inline">\(+1\)</span> siano sopra la frontiera e i rimanenti al disotto. CiÃ² non Ã¨ detto sia a priori possibile, a causa della distribuzione delle caratteristiche, cioÃ¨ non esista tale frontiera come nel caso della Figura 5. {{ insert_image(target, â€˜5â€™, image_location, â€˜Percettrone-Caratteristiche-non-lin-sep.pngâ€™, â€˜Figura 5: Caratteristiche non linearmente separabiliâ€™, â€˜Caratteristiche non linearmente separabiliâ€™) }}</p>
<p>CiÃ² si esprime dicendo che lâ€™insieme di addestramento non Ã¨ <strong><code>linearmente separabile</code></strong> o, in altre parole, che il percettrone commetterÃ  sempre degli errori di classificazione in fase di addestramento, giacchÃ©, per costruzione, puÃ² solo produrre frontiere di decisione lineari. Al contrario, in Figura 4, Ã¨ mostrato un insieme di addestramento linearmente separabile con una possibile, tra le infinite, frontiera di separazione che efficacemente distingue le caratteristiche (in Figura 6 alcuni esempi di frontiere di decisione alternative). {{ insert_image(target, â€˜6â€™, image_location, â€˜Percettrone-Frontiere-multiple.pngâ€™, â€˜Figura 6: Frontiere di decisione multipleâ€™, â€˜Frontiere di decisione multipleâ€™) }}</p>
</section>
<section id="deriva" class="level2" data-number="2.8">
<h2 data-number="2.8" class="anchored" data-anchor-id="deriva"><span class="header-section-number">2.8</span> Deriva</h2>
<p>Il termine deriva Ã¨ usato in matematica e in informatica per rappresentare una sorta di correzione, che viene aggiunta al risultato di un algoritmo. Nella regola di apprendimento del percettrone, si nota che senza la deriva <span class="math inline">\(w_0\)</span>, la frontiera di decisione passerebbe sempre per lâ€™origine dello spazio delle caratteristiche e ciÃ² ne limiterebbe evidentemente la capacitÃ  di separazione di sottoinsiemi degli insiemi di apprendimento.<br>
Per visualizzare questa affermazione, poniamo sempre <span class="math inline">\(n=2\)</span> e facendo riferimento alla Figura 6, dove Ã¨ disegnata la frontiera <span class="math inline">\(w_0+x_1w_1+x_2w_2=0\)</span> con la sua intersezione con lâ€™asse delle ordinate <span class="math inline">\(-\frac{w_0}{w_2}\)</span> che si puÃ² esprimere anche con <span class="math inline">\(\frac{\theta}{w_2}\)</span>, ci si puÃ² convincere che per <span class="math inline">\(w_0=0\)</span> o <span class="math inline">\(\theta=0\)</span>, la frontiera passa per lâ€™origine delle coordinate dello spazio delle caratteristiche. {{ insert_image(target, â€˜7â€™, image_location, â€˜Percettrone-Frontiera-decisione-intercetta.pngâ€™, â€˜Figura 7: Frontiera di decisione e derivaâ€™, â€˜Frontiera di decisione e derivaâ€™) }}</p>
</section>
<section id="convergenza" class="level2" data-number="2.9">
<h2 data-number="2.9" class="anchored" data-anchor-id="convergenza"><span class="header-section-number">2.9</span> Convergenza</h2>
<p>Sappiamo che una condizione necessaria perchÃ© il percettrone possa classificare correttamente lâ€™insieme di addestramento, sia che questo abbia la proprietÃ  di lineare separabilitÃ . Quello che non sappiamo Ã¨ se ciÃ² sia anche sufficiente, cioÃ¨ se Ã¨ garantito che la regola di apprendimento produca un vettore <span class="math inline">\(\mathbf{w}\)</span> senza errori di classificazione e, quindi, sia costruita una frontiera di separazione efficace. E questa Ã¨ proprio la tesi del teorema di convergenza del percettrone pubblicato per la prima volta da Rosenblatt nel 1958 ([RF58II] e [RF62]). &gt; <strong><code>Teorema di convergenza del percettrone</code></strong><br>
&gt; &gt; Per ogni insieme di addestramento, composto da un numero finito di campioni, lâ€™algoritmo di addestramento del percettrone produrrÃ  un vettore <span class="math inline">\(\mathbf{w}\)</span> che classificherÃ  correttamente tutti tali elementi, in un numero finito di epoche.</p>
<p>CiÃ² si esprime anche dicendo che lâ€™algoritmo <strong><code>converge</code></strong> e, usualmente, ciÃ² accade in un numero di iterazioni che Ã¨ di gran lunga superiore alla dimensione dellâ€™insieme di addestramento. Se la condizione del teorema non Ã¨ soddisfatta, allora lâ€™algoritmo continuerÃ  a fare aggiustamenti ai pesi e alla deriva, senza mai raggiungere una soluzione che classifichi correttamente tutti i campioni dellâ€™insieme di addestramento. In questo caso, si dice che lâ€™algoritmo non converge.<br>
Un secondo teorema, piÃ¹ tecnico, dimostrato indipendentemente da Henry Block [BH62] e Aleksey Novikov [NA62], stabilisce un limite superiore al numero di errori di classificazione, il che ci permette di stimare il tempo necessario allâ€™algoritmo per convergere nel caso di insieme di addestramento linearmente separabile.</p>
<blockquote class="blockquote">
<p><strong><code>Teorema del numero massimo di errori del percettrone (Block/Novikov)</code></strong></p>
<p>Assumiamo che lâ€™insieme di addestramento <span class="math inline">\(\Xi\)</span> sia linearmente separabile con margine <span class="math inline">\(\gamma\)</span> e che la lunghezza (o norma euclidea) di tutti i vettori delle caratteristiche, sia minore o uguale di un certo valore <span class="math inline">\(R\)</span> finito (o, piÃ¹ formalmente, <span class="math inline">\(\lVert\mathbf{x}^i\rVertâ‰¤R\ \forall i\)</span>, per <span class="math inline">\(R&gt;0\)</span>). Quindi, il massimo numero di errori compiuti dallâ€™algorimo del percettrone in fase di addestramento, Ã¨ limitato superiormente da <span class="math inline">\(\frac{R^2\lVert\mathbf{w}\rVert^2}{\gamma^2\rVert\widetilde{\mathbf{w}}\lVert^2}\)</span>, con <span class="math inline">\(\mathbf{w}\)</span> vettore dei pesi a convergenza e <span class="math inline">\(\widetilde{\mathbf{w}}\)</span> corrispondente vettore normale alla frontiera di separazione.</p>
</blockquote>
<p>Nel teorema si cita il <strong><code>margine</code></strong> che Ã¨ definito come la distanza minima delle caratteristiche dalla frontiera di decisione in <span class="math inline">\(\mathbb{R}^n\)</span>.<br>
Quindi, adesso sappiamo che il numero massimo di epoche di addestramento Ã¨ limitato superiormente e se si commettesse almeno un errore per epoca (se gli errori fossero zero allora lâ€™algoritmo avrebbe raggiunto la convergenza), allora il numero di epoche sarebbe inferiore a <span class="math inline">\(\frac{R^2\lVert\mathbf{w}\rVert^2}{\gamma^2\rVert\widetilde{\mathbf{w}}\lVert^2}\)</span>. CiÃ² Ã¨ senzâ€™altro confortante ma potrebbe portare ad un valore molto alto e, dâ€™altronde, lâ€™utilitÃ  maggiore del teorema di Block-Novikov Ã¨ nel notare che il limite al numero massimo di errori che esso definisce, Ã¨ indipendente da: * Numero di dimensioni dello spazio delle caratteristiche. * Dimensione dellâ€™insieme di addestramento, cioÃ¨ dal numero dei campioni. * Tasso di apprendimento fintantochÃ© sia mantenuto costante (meno ovvio perchÃ© non citato nella tesi, ma ipotesi nella dimostrazione). * Valore del vettore di inizializzazione di <span class="math inline">\(\mathbf{w}\)</span>. * Ordine dei campioni dellâ€™insieme di addestramento.</p>
<p>Al contrario, Ã¨ dipendente da: * â€˜DifficoltÃ â€™ nella separazione, cioÃ¨ avere <span class="math inline">\(\gamma\)</span> molto bassi (rispetto ai valori delle caratteristiche) incrementa il limite. * La dispersione dei campioni (che porta ad un <span class="math inline">\(R\)</span> elevato).</p>
<p>Il teorema di Block-Novikov Ã¨ interessante perchÃ© pone lâ€™accento sullâ€™importanza di alcune proprietÃ  dellâ€™insieme di addestramento rispetto ad altre, ma Ã¨, al contempo, poco utile operativamente. Infatti, per stimare il limite superiore agli errori abbiamo bisogno di fornire il margine <span class="math inline">\(\eta\)</span>, che non Ã¨ noto a priori e non Ã¨ un risultato dellâ€™addestramento!<br>
Dâ€™altronde, anche ottenendo una stima della frontiera di decisione e del margine, comunque non avremmo alcuna garanzia che siano â€˜vicineâ€™ ai valori di convergenza ottenuti dallâ€™addestramento dellâ€™algoritmo e, soprattutto, nÃ© che tali valori siano ottimali, cioÃ¨ tali da avere il margine massimo o massimizzare una qualsiasi altra metrica di â€˜qualitÃ â€™, sia in addestramento che nella fase seguente di generalizzazione. In generale, il percettrone convergerÃ  ad una delle possibili frontiere di decisione che separano i due insiemi di caratterstiche corripondenti a classi diverse (come visualizzato in Figura 6).</p>
</section>
<section id="generalizzazione" class="level2" data-number="2.10">
<h2 data-number="2.10" class="anchored" data-anchor-id="generalizzazione"><span class="header-section-number">2.10</span> Generalizzazione</h2>
<p>Dopo lâ€™addestramento supervisionato, il percettrone Ã¨ pronto per classificare ingressi di cui la classe Ã¨ ignota. La fase diventa di <strong><code>generalizzazione</code></strong>, definita come la capacitÃ  di estendere la conoscenza del modello acquisita per mezzo dei campioni dellâ€™insieme di addestramento, a nuovi ingressi di cui le relative classi sono sconosciute, collâ€™obiettivo di predire proprio questâ€™ultime, in modo corretto. Questa finalitÃ  Ã¨ la ragione per cui il percettrone e tutti gli altri algoritmi di classificazione, sono sviluppati.<br>
Possiamo definire una regola di generalizzazione, al pari di quella di apprendimento, per definire il calcolo della predizione dato un nuovo ingresso di caratteristiche.</p>
<blockquote class="blockquote">
<p><strong><code>Regola di generalizzazione del percettrone</code></strong> Dato un vettore di caratteristiche <span class="math inline">\(\mathbf{x}\)</span>, la predizione sarÃ  pari a: <span class="math display">\[
\bar{y}=\mathcal{H}\left(\sum_{j=0}^{n}w_j x_j\right).\tag*{\color{blue}{10}}
\]</span></p>
</blockquote>
<p>Dâ€™altronde, la capacitÃ  del percettrone Ã¨ limitata dallâ€™essere un classificatore lineare, il che significa che puÃ² solo apprendere relazioni lineari tra le caratteristiche, quindi se la loro relazione intrinseca fosse non lineare, esso non sarebbe comunque in grado di apprenderla accuratamente e, quindi, avrebbe una scarsa capacitÃ  di generalizzazione, o, in altre parole, commetterebbe un certo numero di errori di predizione. Inoltre, anche la qualitÃ  dei dati di addestramento ha un impatto sulla capacitÃ  di generalizzazione. Se i campioni contengono errori o rumore, o se non sono rappresentativi dellâ€™intera popolazione, il percettrone non avrÃ  una base informativa sufficiente.<br>
Un altro fattore che influisce sulla capacitÃ  di generalizzazione Ã¨ la complessitÃ  del modello fisico, che Ã¨ legata al numero di caratteristiche. Se il numero di caratteristiche Ã¨ troppo grande rispetto al numero di campioni, lâ€™algoritmo puÃ² finire per <code>sovradattarsi</code> ai dati di addestramento, il che significa che apprende perfettamente i dati di addestramento, ma mostra una efficacia limitata o, comunque, nettamente inferiore nella fase di validazione, intermedia tra addestramento e generalizzazione vera e propria. In generale, esistono diverse cause di sovradattamento, che sono meglio connotate con algoritmi piÃ¹ complessi, ma quello che Ã¨ importante sottolineare Ã¨ che il percettrone non ne Ã¨ immune anche se, concettualmente, Ã¨ un algoritmo molto semplice.<br>
Lâ€™errore commesso nella fase di validazione, Ã¨ denominato <strong><code>errore di generalizzazione</code></strong> e il suo calcolo si effettua prendendo un insieme di campioni di caratteristiche e relative classi, non usate in fase di addestramento, e valutando le predizioni senza che i pesi e la deriva siano ulteriormente aggiornati. Quello che si ottiene rappresenta una metrica di qualitÃ  dellâ€™algoritmo nel suo complesso, cioÃ¨, contemporaneamente, della scelta delle caratteristiche del modello e della regola di apprendimento utilizzata, cioÃ¨ dellâ€™algoritmo.</p>
</section>
<section id="insiemi-di-addestramento-non-separabili" class="level2" data-number="2.11">
<h2 data-number="2.11" class="anchored" data-anchor-id="insiemi-di-addestramento-non-separabili"><span class="header-section-number">2.11</span> Insiemi di addestramento non separabili</h2>
<p>Se lâ€™insieme di addestramento non Ã¨ linearmente separabile allora, per sua definizione, non esiste alcuna frontiera di decisione lineare che possa dividere lâ€™insieme in due regioni dove, in ognuna, siano presenti solo caratteristiche corrispondenti alla medesima classe. In questo caso, il percettrone non potrÃ  convergere e, ad ogni iterazione nellâ€™addestramento, produrrÃ  una frontiera con un certo numero di errori associati, qualsiasi sia il numero di iterazioni eseguite. Questa Ã¨ una forma di <strong><code>sottoadattamento</code></strong>, cioÃ¨ il modello Ã¨ troppo semplice per catturare la struttura sottostante dei dati e ciÃ² in un modo aprioristico: Ã¨ lâ€™algoritmo utilizzato che non lo permette.<br>
GiÃ  Marvin Minsky e Seymour Papert, in [MP69], avevano mostrato che, in caso di separabilitÃ  non lineare, il percettrone ricalcolerÃ  continuamente lo stesso vettore di pesi, quindi entrando in un ciclo infinito. CiÃ² comporta la necessitÃ  di algoritmi piÃ¹ avanzati per classificare correttamente tali insiemi di addestramento, come le <strong><code>macchine a vettori di supporto</code></strong>, o altri metodi piÃ¹ avanzati del percettrone.</p>
</section>
<section id="ordine-dei-campioni-in-fase-di-addestramento" class="level2" data-number="2.12">
<h2 data-number="2.12" class="anchored" data-anchor-id="ordine-dei-campioni-in-fase-di-addestramento"><span class="header-section-number">2.12</span> Ordine dei campioni in fase di addestramento</h2>
<p>Durante lâ€™addestramento, il percettrone aggiorna iterativamente i suoi pesi in base agli errori commessi. Questi aggiornamenti sono guidati dalla sequenza di campioni di addestramento forniti. Ecco perchÃ© lâ€™ordine in cui questi campioni vengono presentati, puÃ² influenzare significativamente la velocitÃ  di convergenza e tecniche di modifica di tale ordine riducono significativamente le iterazioni necessarie al raggiungimento della soglia di arresto.<br>
Rispetto alla regola di apprendimento presentata precedentemente, un solo cambiamento viene effettuato e cioÃ¨ lâ€™aggiunta di un passo nellâ€™iterazione sulle epoche, in cui adottiamo una strategia di modifica, o anche una combinazione, dellâ€™ordine dei campioni, che puÃ² includere anche una modifica nel numero di iterazioni nellâ€™epoca, nel caso in cui uno o piÃ¹ campioni vengano omessi o presentati piÃ¹ volte.</p>
<blockquote class="blockquote">
<p><strong><code>Regola di apprendimento del percettrone con ordine dei campioni modificato</code></strong> 1. Inizializza i pesi <span class="math inline">\(\mathbf{w}^0\)</span> a <span class="math inline">\(0\)</span> oppure a piccoli valori casuali, definisci un tasso di apprendimento <span class="math inline">\(\eta\)</span> e un numero massimo di iterazioni <span class="math inline">\(\bar{K}\)</span> o un numero massimo di epoche <span class="math inline">\(\bar{E}\)</span>. 2. Per ogni epoca <span class="math inline">\(E\)</span>: 1. Modifica lâ€™ordine dei campioni dellâ€™insieme di addestramento 2. Per ogni campione <span class="math inline">\((\mathbf{x}^\kappa, y_\kappa)\)</span> dellâ€™insieme di addestramento (<span class="math inline">\(1â‰¤\kappaâ‰¤N\)</span> Ã¨ lâ€™indice positivo sullâ€™insieme di addestramento, <span class="math inline">\(E\)</span> Ã¨ lâ€™indice positivo di epoche, <span class="math inline">\(N\)</span> la dimensione dellâ€™insieme di addestramento e <span class="math inline">\(K=EN+\kappa\)</span> il totale delle iterazioni compiute): 1. Calcola la predizione della classe corrispondente a <span class="math inline">\(\mathbf{x}^\kappa\)</span>: <span class="math display">\[
     \bar{y}_K=\mathcal{H}\left(\sum_{j=0}^{n} w_j^{K-1} x_j^\kappa\right).\tag*{\color{blue}{11}}
     \]</span> 2. Aggiorna i pesi <span class="math inline">\(\mathbf{w}^K\)</span> secondo la formula: <span class="math display">\[
      \mathbf{w}^K=\mathbf{w}^{K-1}+\eta(y_\kappa-\bar{y}_K)\mathbf{x}^\kappa.\tag* {\color{blue}{12}}
      \]</span> 3. Continua fino alla prima occorrenza di una tra le due condizioni seguenti: non vi siano piÃ¹ errori di predizione sullâ€™insieme di addestramento, cioÃ¨ <span class="math inline">\(y_\kappa-\bar{y}_K=0\ \forall \kappa\)</span>, cioÃ¨ in una intera epoca, oppure finchÃ© non sia raggiunto il numero massimo di iterazioni <span class="math inline">\(\bar{K}\)</span> o il numero massimo di epoche <span class="math inline">\(\bar{E}\)</span> (dove <span class="math inline">\(\bar{K}=N\bar{E}\)</span>). 3. Prendi il vettore dei pesi <span class="math inline">\(\mathbf{w}\)</span> per classificare caratteristiche con etichetta ignota nella fase di generalizzazione.</p>
</blockquote>
<p>Abbiamo aggiunto il passo 2.1 che a seconda delle strategie adottate verrÃ  esploso nelle istruzioni necessarie, anche complesse. Alcune strategie: * Rimescolamento degli indici: gli indici vengono permutati con un algoritmo come quello di Fisher-Yates che garantisce una permutazione imparziale, cioÃ¨ ogni possibile permutazione dellâ€™elenco degli indici ha la stessa probabilitÃ  di occorrenza. Ãˆ implementato dalla funzione <code>random.shuffle</code> in Python. Vi sono alternative piÃ¹ complesse. * Ciclo: in pratica ad ogni epoca si parte dallâ€™elemento successivo a quello usato nella precedente (gli indici sono ottenuti dalla operazione <span class="math inline">\(i+1 \bmod n\)</span>, se <span class="math inline">\(i\)</span> Ã¨ lâ€™indice dellâ€™ultima sequenza). * Massima distanza: ad ogni epoca dividiamo in due sottoinsiemi lâ€™insieme di addestramento: quello coi campioni non correttamente classificati e il complementare. Il primo lo ordiniamo per distanza decrescente <span class="math inline">\(\frac{-y_\kappa\langle\mathbf{w}^K, \mathbf{x}^\kappa\rangle}{\lVert\widetilde{\mathbf{w}}^K\rVert}\)</span> dalla ultima frontiera di decisione (quindi il primo sarÃ  quello â€˜piÃ¹â€™ erroneamente classificato). Il secondo sottoinsieme per distanza crescente <span class="math inline">\(\frac{y_\kappa\langle\mathbf{w}^K, \mathbf{x}^\kappa\rangle}{\lVert\widetilde{\mathbf{w}}^K\rVert}\)</span> dalla frontiera di decisione o rimescolati. Lâ€™ordine nellâ€™epoca sarÃ  dato dal primo sottoinsieme seguito dal secondo. * Massimo residuo: si ordinano i campioni sulla base dellâ€™errore, in valore assoluto, commesso prima dellâ€™applicazione della funzione di attivazione alla predizione <span class="math inline">\(|\langle\mathbf{w}^K,\mathbf{x}^\kappa\rangle-y^\kappa|\)</span>, a partire dal massimo e poi via via in modo decrescente.</p>
<p>Da notare come le prime due strategie siano indipendenti dalle caratteristiche, dato che agiscono sui soli indici, mentre quelle di massima distanza e residuo, dipendano dai campioni. Inoltre, possono essere anche combinate come, ad esempio, la massima distanza per i campioni classificati erroneamente e il rimescolamento per quelli correttamente classificati.</p>
</section>
<section id="oltre-la-classificazione-binaria" class="level2" data-number="2.13">
<h2 data-number="2.13" class="anchored" data-anchor-id="oltre-la-classificazione-binaria"><span class="header-section-number">2.13</span> Oltre la classificazione binaria</h2>
<p>Nel caso di problemi con un numero di classi maggiore di due, possiamo usare delle tecniche di riduzione al caso binario, tra cui: * <strong><code>Uno contro tutti</code></strong>: Addestriamo tanti percettroni quante classi e ognuno sarÃ  associato ad una classe che diventerÃ  il â€˜caso positivoâ€™ (classe <span class="math inline">\(+1\)</span>) e tutte le altre corrisponderanno al â€˜caso negativoâ€™ (classe <span class="math inline">\(-1\)</span>). Tutti gli insiemi di addestramento risulteranno <strong><code>sbilanciati</code></strong>, se lâ€™insieme di partenza avrÃ  un numero di campioni per classe simile. CiÃ², in generale, vedremo essere una condizione non ottimale. * <strong><code>Uno contro uno</code></strong>: per ogni coppia di classi, addestriamo un percettrone e, pertanto, in totale saranno <span class="math inline">\(\binom{\Sigma}{2}=\frac{\Sigma(\Sigma-1)}{2}\)</span>, ove <span class="math inline">\(\Sigma\)</span> Ã¨ il numero delle classi. CiÃ² significa che il numero di percettroni aumenta col quadrato del numero di classi, ma lâ€™addestramento di ognuno Ã¨ su un numero di campioni inferiore.</p>
<p>Identificheremo le varie alternative di riduzione al caso binario sotto il termine comune di <strong><code>percettrone multiclasse</code></strong>.</p>
<section id="uno-contro-tutti" class="level3" data-number="2.13.1">
<h3 data-number="2.13.1" class="anchored" data-anchor-id="uno-contro-tutti"><span class="header-section-number">2.13.1</span> Uno contro tutti</h3>
<section id="regola-di-apprendimento-1" class="level4" data-number="2.13.1.1">
<h4 data-number="2.13.1.1" class="anchored" data-anchor-id="regola-di-apprendimento-1"><span class="header-section-number">2.13.1.1</span> Regola di apprendimento</h4>
<p>Lâ€™ insieme di dati di addestramento ha sempre la forma <span class="math inline">\(\color{blue}\fbox{6}\)</span> con lâ€™unica differenza che adesso <span class="math inline">\(y_i\)</span> puÃ² assumere <span class="math inline">\(\Sigma\)</span> valori anzichÃ© due, con <span class="math inline">\(\Sigma&gt;2\)</span>. Chiameremo il percettrone che classifica la classe <span class="math inline">\(\sigma\)</span>-esima (con <span class="math inline">\(1â‰¤\sigmaâ‰¤\Sigma\)</span>) come â€˜percettrone <span class="math inline">\(\sigma\)</span>â€™ e i suoi parametri e iperparametri avranno <span class="math inline">\(\sigma\)</span> come apice o pedice.<br>
Definiamo le <span class="math inline">\(\Sigma\)</span> classi come <span class="math inline">\(\alpha_\sigma\)</span> e lâ€™insieme contenente tali classi come <span class="math inline">\(A\)</span>, quindi la funzione di attivazione del percettrone <span class="math inline">\(\sigma\)</span> diventa: <span class="math display">\[
\bar{\mathcal{h}}=\mathcal{H}(\langle\mathbf{w}_\sigma, \mathbf{x}\rangle) =
\begin{cases}
1 &amp; \implies \bar{y}=\alpha_\sigma, &amp; \langle\mathbf{w}_\sigma,\mathbf{x}\rangle \geq 0 \vphantom{\underset{i\neq\sigma}{\lor}},\ &amp;\alpha_{\sigma}\in A \\
-1 &amp; \implies \bar{y}=\smash{\underset{i\neq\sigma}{\lor}}\bar{\alpha}_i, &amp;\langle\mathbf{w}_\sigma, \mathbf{x}\rangle &lt; \theta
\end{cases}
\tag*{\color{blue}{13}}
\]</span> cioÃ¨ se lâ€™argomento della funzione Ã¨ non negativo, allora la classe predetta <span class="math inline">\(\bar{y}\)</span> Ã¨ <span class="math inline">\(\alpha_\sigma\)</span>, mentre se lâ€™argomento Ã¨ negativo, allora la predizione ci dice solo che Ã¨ una delle classi diverse da <span class="math inline">\(\alpha_\sigma\)</span>, ma non quale tra le classi appartenenti allâ€™insieme <span class="math inline">\(A\setminus\{\alpha_{\sigma}\}\)</span> di tutti gli elementi di <span class="math inline">\(A\)</span> diversi da <span class="math inline">\(\alpha_{\sigma}\)</span>.<br>
Prima di continuare con la regola di apprendimento, facciamo un esempio con tre etichette: â€˜rossoâ€™, â€˜verdeâ€™ e â€˜bluâ€™ a cui corrisponderanno le classi <span class="math inline">\(\alpha_{rosso}\)</span>, <span class="math inline">\(\alpha_{verde}\)</span> e <span class="math inline">\(\alpha_{blu}\)</span>. Quindi, avremo tre percettroni e ad esempio per il â€˜rossoâ€™:<br>
<span class="math display">\[
\bar{\mathcal{h}}=\mathcal{H}_{rosso}(\langle\mathbf{w}_{rosso}, \mathbf{x}\rangle)=\begin{cases} 1\ &amp;\implies \bar{y}=\alpha_{rosso}, &amp; \langle\mathbf{w}_{rosso}, \mathbf{x}\rangleâ‰¥0 \\ -1\ &amp;\implies \bar{y}\ =\alpha_{verde}\lor\alpha_{blu}, &amp; \langle\mathbf{w}_{rosso}, \mathbf{x}\rangle&lt;Î¸ \end{cases}\tag*{\color{blue}{14}}
\]</span> da cui si evince che il â€˜percettrone rossoâ€™ predice o la classe con etichetta rosso o quella con etichetta verde o blu. Per semplicitÃ  abbiamo sostituito alla classe lâ€™etichetta, considerata la corrispondenza biunivoca tra di esse. Pertanto, la regola di apprendimento diviene:</p>
<blockquote class="blockquote">
<p><strong><code>Regola di apprendimento del percettrone multiclasse 'uno contro tutti'</code></strong> 1. Inizializza i pesi <span class="math inline">\(\mathbf{w}^0_\sigma\)</span> per ogni percettrone <span class="math inline">\(\sigma\)</span>, con <span class="math inline">\(\sigma \in \Sigma\)</span>, a <span class="math inline">\(0\)</span> oppure a piccoli valori casuali, definisci un tasso di apprendimento <span class="math inline">\(\eta\)</span> e un numero massimo di epoche <span class="math inline">\(\bar{E}\)</span> o una soglia minima di errore come somma di tutti gli errori commessi dai percettroni o definita dal massimo tra tutti i percettroni. 2. Per ogni epoca <span class="math inline">\(E\)</span>: 1. Per ogni campione <span class="math inline">\((\mathbf{x}^\kappa, y_\kappa)\)</span> dellâ€™insieme di addestramento (<span class="math inline">\(\kappa\)</span> con <span class="math inline">\(1â‰¤\kappaâ‰¤N\)</span> Ã¨ lâ€™indice positivo sullâ€™insieme di addestramento <span class="math inline">\(\Xi\)</span> che ha dimensione <span class="math inline">\(N\)</span>, <span class="math inline">\(E\)</span> Ã¨ lâ€™indice positivo di epoche e <span class="math inline">\(K=EN+\kappa\)</span>, il totale delle iterazioni compiute): 1. Per ogni percettrone <span class="math inline">\(\sigma\)</span>: 1. Calcola la predizione corrispondente allâ€™ingresso <span class="math inline">\(\mathbf{x}^\kappa\)</span>: <span class="math display">\[
          \bar{\mathcal{h}}_K=\mathcal{H}\left(\langle\mathbf{w}^{K-1}_{\sigma},\mathbf{x}^\kappa\rangle\right)\tag*{\color{blue}{15}}
          \]</span> 2. Ricava dalla classe â€˜veraâ€™ <span class="math inline">\(y_{\kappa}\in A\)</span> il corrispondente valore <span class="math inline">\(\mathcal{h}_{\kappa}=\pm1\)</span>, usando la corrispondenza tra <span class="math inline">\(1\)</span> e <span class="math inline">\(\alpha_{\sigma}\)</span> e <span class="math inline">\(,-1\)</span> e <span class="math inline">\({\underset{i\neq\sigma}{\lor}}\bar{\alpha}_i\)</span>: <span class="math display">\[
          \begin{align}y_{\kappa}=\alpha_{\sigma}&amp;\implies h_{\kappa}=1\\y_{\kappa}\neq\alpha_{\sigma}&amp;\implies h_{\kappa}=-1\end{align}.\tag*{\color{blue}{16}}
          \]</span> 3. Aggiorna i pesi <span class="math display">\[
          \mathbf{w}^K_{\sigma}=\mathbf{w}^{K-1}_{\sigma}+\eta(\mathcal{h}_{\kappa}-\bar{\mathcal{h}}_K)\mathbf{x}^{\kappa}\tag*{\color{blue}{17}}.
          \]</span> 2. Ripeti il passo 1 per un numero predefinito di epoche o fino a quando lâ€™errore ad una certa iterazione non abbia raggiunto la soglia predefinita. 3. Prendi i <span class="math inline">\(\Sigma\)</span> vettori di pesi&nbsp;<span class="math inline">\(\mathbf{w}_\sigma\)</span>&nbsp;per classificare caratteristiche con etichetta ignota nella fase di generalizzazione.</p>
</blockquote>
<p>Ritorniamo allâ€™esempio dellâ€™insieme colle etichette rosso, verde e blu. Supponiamo che le corrispondenti classi siano 1, 2, 3. Supponiamo che <span class="math inline">\(y_{\kappa}=2\)</span> (etichetta verde), allora la regola di addestramento allâ€™iterazione <span class="math inline">\(K\)</span> si traduce in: * Percettrone rosso: se <span class="math inline">\(\langle\mathbf{w}^{K-1}_{rosso},\mathbf{x}^\kappa\rangleâ‰¥0\)</span>, allora predice <span class="math inline">\(+1\)</span>, quindi rosso, cioÃ¨ commette un errore. Dâ€™altronde il valore vero dellâ€™etichetta Ã¨ verde quindi <span class="math inline">\(h_K=-1\)</span> e i pesi sono effettivamente aggiornati <span class="math inline">\(\mathbf{w}^K_{rosso}=\mathbf{w}^{K-1}_{rosso}-2\eta\mathbf{x}^{\kappa}\)</span>. Se <span class="math inline">\(\langle\mathbf{w}^{K-1}_{rosso},\mathbf{x}^\kappa\rangle&lt;0\)</span> allora i pesi rimangono invariati, giacchÃ© la predizione Ã¨ corretta. * Percettrone verde: se <span class="math inline">\(\langle\mathbf{w}^{K-1}_{verde},\mathbf{x}^\kappa\rangleâ‰¥0\)</span>, allora predice <span class="math inline">\(+1\)</span>, quindi verde, correttamente e i pesi non sono aggiornati. Se <span class="math inline">\(\langle\mathbf{w}^{K-1}_{verde},\mathbf{x}^\kappa\rangle&lt;0\)</span> allora predice rosso o blu, quindi commette un errore. I pesi sono da aggiornare con <span class="math inline">\(h_K=1\)</span> cioÃ¨ <span class="math inline">\(\mathbf{w}^K_{verde}=\mathbf{w}^{K-1}_{verde}+2\eta\mathbf{x}^{\kappa}\)</span>. * Percettrone blu: come il rosso.</p>
</section>
</section>
<section id="generalizzazione-1" class="level3" data-number="2.13.2">
<h3 data-number="2.13.2" class="anchored" data-anchor-id="generalizzazione-1"><span class="header-section-number">2.13.2</span> Generalizzazione</h3>
<p>Supponiamo che il percettrone multiclasse abbia terminato addestramento, adesso puÃ² essere impiegato su caratteristiche non giÃ  â€˜visteâ€™. Prima perÃ² dobbiamo definire una sorta di regola di generalizzazione che, dato un ingresso, permetta di ottenere la classe di uscita.<br>
Se tutti i percettroni hanno raggiunto la convergenza e supponendo che la classe corrispondente al nuovo ingresso <span class="math inline">\(\mathbf{x}\)</span> sia <span class="math inline">\(\alpha_{\hat{\sigma}}\)</span>, allora il percettrone <span class="math inline">\(\hat{\sigma}\)</span> dovrebbe classificarlo con <span class="math inline">\(+1\)</span> e tutti gli altri con <span class="math inline">\(-1\)</span>: <span class="math display">\[
\begin{align}\langle\mathbf{w}_{\sigma},\mathbf{x}\rangle&amp;â‰¥0, \ \sigma=\hat{\sigma}\\\langle\mathbf{w}_{\sigma},\mathbf{x}\rangle&amp;&lt;0,\ \forall\sigma\neq\hat{\sigma} \end{align}\tag*{\color{blue}{18}}
\]</span> che, in modo piÃ¹ compatto, si puÃ² esprimere con <span class="math display">\[
\hat{\sigma}=\underset{1â‰¤\sigmaâ‰¤\Sigma}{\mathrm{argmax}}\left(\langle\mathbf{w}_{\sigma},\mathbf{x}\rangle\right).\tag*{\color{blue}{19}}
\]</span> Tornando allâ€™esempio delle etichette dei colori, supponiamo di avere un campione <span class="math inline">\((x,2)\)</span> (dove <span class="math inline">\(2\)</span> era la classe dellâ€™etichetta verde), allora, sempre nella condizione di classificazione corretta da parte di tutti i percettroni: * Percettrone rosso: <span class="math inline">\(\langle\mathbf{w}_{rosso},\mathbf{x}\rangle&lt;0\)</span>. * Percettrone verde: <span class="math inline">\(\langle\mathbf{w}_{verde},\mathbf{x}\rangleâ‰¥0\)</span>. * Percettrone blu: <span class="math inline">\(\langle\mathbf{w}_{blu},\mathbf{x}\rangle&lt;0\)</span>.</p>
<p>La <span class="math inline">\(\color{blue}\fbox{19}\)</span> in questo caso restituisce <span class="math inline">\(2\)</span>, cioÃ¨ lâ€™etichetta verde, dato che il massimo Ã¨ tra un valore positivo (quello del percettrone verde) e due negativi, quindi il comportamento della formula Ã¨ coerente con le nostre aspettative.<br>
In generale, la <span class="math inline">\(\color{blue}\fbox{19}\)</span> Ã¨ la formula utilizzata per la generalizzazione del percettrone multiclasse in versione â€˜uno contro tuttiâ€™, per determinare la classe corrispondente ad un nuovo ingresso e, come abbiamo visto, nel caso ideale si comporta correttamente.<br>
Dâ€™altronde, se uno o piÃ¹ percettroni non hanno raggiunto la convergenza o lâ€™insieme di addestramento non Ã¨ linearmente separabile, oppure, nella condizione ideale, comunque commettono un errore di predizione, allora non varranno piÃ¹ le <span class="math inline">\(\color{blue}\fbox{18}\)</span> nel senso che sia il percettrone corrispopndente alla classe â€˜veraâ€™ potrebbe fallire, o gli altri classificarlo erroneamente. In tutti questi casi, la <span class="math inline">\(\color{blue}\fbox{19}\)</span> Ã¨ la scelta piÃ¹ ragionevole perchÃ© sfrutta il massimo della conoscenza acquisita dal percettrone multiclasse.<br>
Va perÃ² notato che non tutte le regioni dello spazio delle caratteristiche portano alla definizione di una unica classe come risultato.</p>
</section>
<section id="uno-contro-uno" class="level3" data-number="2.13.3">
<h3 data-number="2.13.3" class="anchored" data-anchor-id="uno-contro-uno"><span class="header-section-number">2.13.3</span> Uno contro uno</h3>
<section id="regola-di-apprendimento-2" class="level4" data-number="2.13.3.1">
<h4 data-number="2.13.3.1" class="anchored" data-anchor-id="regola-di-apprendimento-2"><span class="header-section-number">2.13.3.1</span> Regola di apprendimento</h4>
<p>In questo caso addestreremo un percettrone per ogni coppia di classi distinte <span class="math inline">\(\upsilon\)</span> e <span class="math inline">\(\tau\)</span> tra le <span class="math inline">\(\Sigma\)</span>, e lo chiameremo percettrone <span class="math inline">\(\upsilon\tau\)</span>.</p>
<blockquote class="blockquote">
<p><strong><code>Regola di apprendimento del percettrone multiclasse 'uno contro uno'</code></strong> 1. Per ogni percettrone <span class="math inline">\(\upsilon\tau\)</span>, seleziona dallâ€™insieme di addestramento <span class="math inline">\(\Xi\)</span> solo i campioni che hanno <span class="math inline">\(\upsilon\)</span> e <span class="math inline">\(\tau\)</span> come classi e tale sottoinsieme sia <span class="math inline">\(\Xi_{\upsilon\tau}\)</span> e il campione generico <span class="math inline">\((\mathbf{x}_{\upsilon\tau},y_{\upsilon\tau})\)</span>. 2. Inizializza i pesi <span class="math inline">\(\mathbf{w}^0_{\upsilon\tau}\)</span>, per ogni percettrone <span class="math inline">\(\upsilon\tau\)</span>, a <span class="math inline">\(0\)</span> oppure a piccoli valori casuali, definisci un tasso di apprendimento <span class="math inline">\(\eta\)</span> e un numero massimo di epoche <span class="math inline">\(\bar{E}\)</span> o una soglia minima di errore come somma di tutti gli errori commessi dai percettroni o definita dal massimo tra tutti i percettroni. 3. Per ogni epoca <span class="math inline">\(E\)</span>: 1. Per ogni percettrone <span class="math inline">\(\upsilon\tau\)</span>: 1. Per ogni campione <span class="math inline">\((\mathbf{x}^\kappa_{\upsilon\tau}, y_{\upsilon\tau,\kappa})\)</span> dellâ€™insieme di addestramento (<span class="math inline">\(\kappa\)</span> con <span class="math inline">\(1â‰¤\kappaâ‰¤N_{\upsilon\tau}\)</span> Ã¨ lâ€™indice positivo sullâ€™insieme di addestramento <span class="math inline">\(\Xi_{\upsilon\tau}\)</span> , <span class="math inline">\(E\)</span> Ã¨ lâ€™indice positivo di epoche, <span class="math inline">\(N_{\upsilon\tau}\)</span> la dimensione dellâ€™insieme di addestramento e <span class="math inline">\(K=EN_{\upsilon\tau}+\kappa\)</span> il totale delle iterazioni compiute): 2. Calcola la predizione della classe corrispondente a <span class="math inline">\(\mathbf{x}^\kappa_{\upsilon\tau}\)</span>: <span class="math display">\[
          \bar{y}_{\upsilon\tau,K}=\mathcal{H}\left(\sum_{j=0}^{n} w_{\upsilon\tau,j}^{K-1} x_{\upsilon\tau,j}^\kappa\right).\tag*{\color{blue}{20}}
          \]</span> 3. Aggiorna i pesi <span class="math inline">\(\mathbf{w}^K_{\upsilon\tau}\)</span> secondo la formula: <span class="math display">\[
          \mathbf{w}^K_{\upsilon\tau}=\mathbf{w}^{K-1}_{\upsilon\tau}+\eta(y_{\upsilon\tau,\kappa}-\bar{y}_{\upsilon\tau,K})\mathbf{x}^\kappa_{\upsilon\tau}.\tag* {\color{blue}{21}}
          \]</span> 2. Ripeti il passo 1 per un numero predefinito di epoche o fino a quando lâ€™errore ad una certa iterazione non abbia raggiunto la soglia predefinita. 4. Prendi i <span class="math inline">\(\binom{\Sigma}{2}\)</span> vettori di pesi&nbsp;<span class="math inline">\(\mathbf{w}_{\upsilon\tau}\)</span>&nbsp;per classificare caratteristiche con etichetta ignota nella fase di generalizzazione.</p>
</blockquote>
</section>
<section id="generalizzazione-2" class="level4" data-number="2.13.3.2">
<h4 data-number="2.13.3.2" class="anchored" data-anchor-id="generalizzazione-2"><span class="header-section-number">2.13.3.2</span> Generalizzazione</h4>
<p>La formula di generalizzazione conta i â€˜votiâ€™ dei percettroni binari e la classe con piÃ¹ voti, Ã¨ quella risultante della classificazione. In particolare, per ogni percettrone <span class="math inline">\(\upsilon\tau\)</span>, si calcola la predizione <span class="math inline">\(\bar{y}_{\upsilon\tau}\)</span> e si assegna un voto alla classe che corrisponde al risultato (quindi 1 voto a <span class="math inline">\(\upsilon\)</span> o <span class="math inline">\(\tau\)</span>), e cosÃ¬ si ottiene elenco di classi con relativo totale di voti di cui prendere il massimo.<br>
Per quanto sia semplice, tale procedura porta a delle ambiguitÃ , perchÃ© nel caso due o piÃ¹ classi ottengano lo stesso numero di voti, sarÃ  necessario un ulteriore criterio per ridurre tale molteplicitÃ  ad una.</p>
</section>
</section>
<section id="utilitÃ " class="level3" data-number="2.13.4">
<h3 data-number="2.13.4" class="anchored" data-anchor-id="utilitÃ "><span class="header-section-number">2.13.4</span> UtilitÃ </h3>
<p>Il percettrone multiclasse Ã¨ stato presentato al fine di mostrare alcune possibili estensioni del binario, ma le limitazioni di questâ€™ultimo appaiono come amplificate e tali da rendere la versione multiclasse poco interessante, rispetto ad alternative come le macchine a vettori di supporto, gli alberi di decisione o anche le reti neurali profonde, per citare solo alcuni tra gli strumenti di classificazione piÃ¹ potenti.<br>
Inoltre, gli algoritmi di apprendimento o di predizione non aggiungono granchÃ© su un piano strettamente didattico, per questo rimandiamo ad una trattazione piÃ¹ completa nelle prossime lezioni.</p>
</section>
</section>
<section id="elementi-chiave-della-lezione" class="level2" data-number="2.14">
<h2 data-number="2.14" class="anchored" data-anchor-id="elementi-chiave-della-lezione"><span class="header-section-number">2.14</span> Elementi chiave della lezione</h2>
<ol type="1">
<li>Abbiamo introdotto alcuni concetti importanti dellâ€™apprendimento delle macchine e cioÃ¨ i classificatori lineari, lâ€™apprendimento supervisionato, la regola e lâ€™insieme di apprendimento, la generalizzazione e il suo errore, la deriva, la funzione di attivazione. Essendo concetti generali Ã¨ importante che siano compresi profondamente, sfruttando la semplicitÃ  dellâ€™algoritmo del percettrone.</li>
<li>Altri concetti, ugualmente importanti come la frontiera di decisione e il margine appartenenti al novero dei classificatori, saranno ugualmente ripresi, anche se con un corredo di nozioni piÃ¹ articolato.</li>
<li>Abbiamo formulato lâ€™algoritmo del percettrone in un modo che possa essere implementato in un linguaggio di programmazione arbitario.</li>
</ol>
</section>
<section id="prossimo-passo" class="level2" data-number="2.15">
<h2 data-number="2.15" class="anchored" data-anchor-id="prossimo-passo"><span class="header-section-number">2.15</span> Prossimo passo</h2>
<p>Percettrone - Implementazione Python Percettrone - Temi Avanzati Macchine a vettori di supporto</p>
</section>
<section id="per-approfondire" class="level2" data-number="2.16">
<h2 data-number="2.16" class="anchored" data-anchor-id="per-approfondire"><span class="header-section-number">2.16</span> Per approfondire</h2>
<section id="documenti-storici-sul-percettrone" class="level3" data-number="2.16.1">
<h3 data-number="2.16.1" class="anchored" data-anchor-id="documenti-storici-sul-percettrone"><span class="header-section-number">2.16.1</span> Documenti storici sul percettrone</h3>
<p>Il progetto PARA fu lanciato da Rosenblatt al Cornell Aeronautical Laboratory nel 1956 col duplice obiettivo: dimostrare la fattibilitÃ  di una nuova tecnica statistica e testare la â€˜funzionalitÃ â€™ di quella tecnica su hardware ad hoc, come il MARK I. In particolare, mirava a stabilire la fattibilitÃ  tecnica ed economica di un â€˜analogo del cervelloâ€™, in grado di riconoscere strutture simili di informazioni ottiche, elettriche o sonore. Negli anni 1956-1962 approfondirÃ  in diversi report, pubblicazioni e libri il contesto teorico del percettrone, generando anche significative aspettative.<br>
Il percettrone, cosÃ¬ come presentato da Rosenblatt e da altri autori, Ã¨ piuttosto diverso da quello formalizzato sopra, perchÃ© le generalizzazioni teoriche seguenti hanno â€˜depuratoâ€™ le supposte analogie con il cervello umano, con un formalismo che permette la focalizzazione sulle proprietÃ  matematiche di algoritmi simulabili su macchine enormemente piÃ¹ potenti rispetto a quelle degli anni â€™50 e â€™60. Inoltre, Rosenblatt intendeva il percettrone come una macchina che completÃ² nel 1960 e chiamÃ² Mark I, anche se usÃ² lâ€™IBM 704 per effettuare una simulazione informatica e mostrare le potenzialitÃ  dellâ€™algoritmo ([CM21]).</p>
<p>[RF58I] Rosenblatt, Frank (1957).&nbsp;<code>The Perceptron â€” A Perceiving and Recognizing Automaton (Project PARA)</code>. Tech. Rep.&nbsp;85-460-1. Cornell Aeronautical Laboratory. <em>La prima pubblicazione con il termine percettrone e gli obiettivi di ricerca di Rosenblatt.</em> &gt; <em>Recent theoretical studies by this writer indicate that it should be feasible to construct an electronic or electromechanical system which will learn to recognize similarities or identities between patterns of optical, electrical, or tonal information, in a manner which may be closely analogous to the perceptual processes of a biological brain. The proposed system depends on probabilistic rather than deterministic principles for its operation, and gains its reliability from the properties of statistical measurements obtained from large populations of elements. A system which operates according to these principles will be called a&nbsp;<strong>perceptron</strong>. (Pag. 2)</em> &gt; &gt; <em>Recenti studi teorici di questo autore indicano che dovrebbe essere fattibile costruire un sistema elettronico o elettromeccanico che imparerÃ  a riconoscere somiglianze o identitÃ  tra modelli di informazioni ottiche, elettriche o sonore, in un modo che puÃ² essere strettamente analogo ai processi percettivi di un cervello biologico. Il sistema proposto si basa su principi probabilistici piuttosto che deterministici per il suo funzionamento, e guadagna la sua affidabilitÃ  dalle proprietÃ  delle misure statistiche ottenute da grandi popolazioni di elementi. Un sistema che opera secondo questi principi sarÃ  chiamato perceptron. (Pag. 2)</em></p>
<p>[RF58I] Rosenblatt, Frank (1958).&nbsp;<code>The perceptron: A theory of statistical separability in cognitive systems (Project PARA)</code>. U.S. Dept. of Commerce, Office of Technical Services.</p>
<p>[RF58II] Rosenblatt, Frank (1958). <code>The perceptron: A probabilistic model for information storage and organization in the brain</code>. Psychological Review.&nbsp;65&nbsp;(6): 386â€“408.&nbsp;DOI:<a href="https://doi.org/10.1037%2Fh0042519">10.1037/h0042519</a>.</p>
<p>[RF58III] Rosenblatt, Frank (1958). <code>Two theorems of statistical separability in the perceptron (Project PARA)</code>.&nbsp;Cornell Aeronautical Laboratory, Inc.</p>
<p>[RF62] Rosenblatt, Frank (1962).&nbsp;<code>Principles of neurodynamics: perceptrons and the theory of brain mechanisms</code>.&nbsp;Spartan Books.</p>
<p>[BH62] Block, Henry (1962). <code>The Perceptron: A Model for Brain Functioning. I</code>. Reviews of Modern Physics. 34, 123-135. DOI: <a href="https://doi.org/10.1103/RevModPhys.34.123">10.1103/RevModPhys.34.123</a>.</p>
<p>[NA62] Novikov, Albert B. J. (1962). <code>On convergence proofs on perceptrons</code>. Proceedings of the Symposium on the Mathematical Theory of Automata. Vol. XII: 615â€“622.</p>
<p>[MP69] Minsky, Marvin &amp; Papert, Seymour (1969). <code>Perceptrons: An Introduction to Computational Geometry</code>. MIT Press. ISBN: 0-262-63022-2/978-0-262-63022-1.</p>
<p>[MP17] Minsky, Marvin &amp; Papert, Seymour (2017). <code>Perceptrons: An Introduction to Computational Geometry. Reissue of the 1988 Expanded Edition with a new foreword by LÃ©on Bottou</code>. MIT Press. ISBN: 0-262-53477-0/978-0-262-53477-2.</p>
</section>
<section id="storia-dellapprendimento-delle-macchine" class="level3" data-number="2.16.2">
<h3 data-number="2.16.2" class="anchored" data-anchor-id="storia-dellapprendimento-delle-macchine"><span class="header-section-number">2.16.2</span> Storia dellâ€™apprendimento delle macchine</h3>
<p>[NN09] Nilsson, Nils J. (2009).&nbsp;<code>The Quest for Artificial Intelligence</code>. Cambridge University Press. ISBN: 9780511819346. DOI: <a href="https://doi.org/10.1017/CBO9780511819346">10.1017/CBO9780511819346</a>. <a href="https://ai.stanford.edu/~nilsson/QAI/qai.pdf">PDF</a></p>
<p>[CM21] Metz, Cade (2021). <code>Genius Makers:&nbsp;The Mavericks who Brought AI to Google, Facebook and the World</code>. Dutton. ISBN: 9781847942135. <em>Ed. It</em>. (2022). <code>Costruire l'intelligenza. Google, Facebook, Musk e la sfida del futuro</code>. Mondadori. ISBN: 9788804745839.</p>
</section>
<section id="manuali" class="level3" data-number="2.16.3">
<h3 data-number="2.16.3" class="anchored" data-anchor-id="manuali"><span class="header-section-number">2.16.3</span> Manuali</h3>
<p>[AS23] Axler, Sheldon (2023). <code>Linear Algebra Done Right</code>. Springer. DOI: <a href="https://doi.org/10.1007/978-3-031-41026-0">10.1007/978-3-031-41026-0</a>. ISBN: 978-3-031-41025-3. <a href="https://link.springer.com/content/pdf/10.1007/978-3-031-41026-0.pdf">PDF</a></p>
<p>[MR22] Hardt, Moritz &amp; Recht, Benjamin (2022). <code>Patterns, Predictions, and Actions: Foundations of Machine Learning</code>. Princeton University Press. ISBN: 9780691233734. <a href="https://mlstory.org/pdf/patterns.pdf">PDF</a></p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/antomon\.github\.io\/corso-apprendimento-automatico\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./basi-apprendimento-supervisionato.html" class="pagination-link" aria-label="Basi dell'apprendimento supervisionato">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text">Basi dellâ€™apprendimento supervisionato</span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./summary.html" class="pagination-link" aria-label="Summary">
        <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Summary</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>